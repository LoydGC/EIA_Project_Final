---
title: "The Shifting Landscape of Clean Energy"
author: "Gavin Loyd"
course: "Python Programming II (90-819)"
institution: "Carnegie Mellon University, Heinz College"
date: "October 11, 2025"
format: 
  html:
    toc: true
    toc-expand: 1
---
## Executive Summary

U.S. generation capacity moves with policy and technology cycles. This study combines **EIA** operating-generator data and the **MISO** interconnection queue to show how capacity has shifted and where it is headed. Methods: **time-series analysis**, **state/county geography**, and **descriptive statistics** centered on **nameplate capacity**, **technology**, and a **clean/non-clean** flag.

---

## Key Findings

1. **No single technology is untouchable.** Additions swing with policy and innovation.
2. **Clean buildout is uneven.** The West leads; several Eastern states lag.
3. **Renewables are more dispersed.** They span more counties than legacy thermal.
4. **Policy is decisive.** Incentives and permitting shape outcomes; markets alone do not.

## Introduction & Methodology

The green transition is a defining phenomenon of the 21st-century United States. Scientists, politicians, and activists have consistently vocalized an urgent need to reduce emissions to meet various climate targets before we pass various thresholds of no return. For decades, the policy apparatus and the private sector have put forward a plethora of mechanisms to meet climate goals such as carbon trading schemes, renewable portfolio standards, clean technology subsidies, and permitting reform. 

At its most basic level. the green transition is decided by the make-up of the electricity market. If the generators do not get cleaner, then all actors interested in meeting their climate targets have no avenue to do so. Accordingly, it is critical to understand the limitations and successes of the green transition in terms of the physical infrastructure built and installed to produce electricity. This study interrogates the green trends we are seeing in the electricity sector.

### Research Question and Objectives


**Primary research question:** What trends can we identify in the available capacity for power plants, especially in terms of clean energy?

**Objectives:**
This analysis attempts to answer the above research question by quantifying and breaking it down into the following smaller questions:
<ol type="a">
  <li>What has the US fuel mix historically looked like?</li>
  <li>Do we see noticeable changes in available capacity following technological booms and policy shocks?</li>
  <li>How are different types of power plants geographically distributed and what are the implications for capital flow to communities?</li>
  <li>Does the evidence suggest the US fuel mix is becoming cleaner over time?</li>
</ol>

The general hypothesis is that there has been extensive "greening" of the electricity market with very clear spikes in recent years. However, a more hostile policy environment following the elimination of much of the Inflation Reduction Act, a punitive permitting regime, and incentives for competitor energy sources in the past 6 months should show itself in the data. Renewables are more geographically distributed than more traditional energy sources like coal, natural gas, and nuclear due to their unique access to their respective fuels and the energy density of traditional energy sources.

### Data Collection and Sources

This study uses two datasets to conduct its analysis:

**The Energy Information Administration Inventory of Operable Generators** - The raw data is sourced from the EIA API and covers 27,219 generators and 26 columns from the July Operating Generator Monthly Survey. The clean dataframe is 10,772 generators and 12 columns. This clean dataset is a subset of generators 10 MW or above to make this a utility-scale dataset and apples-to-apples with the MISO data. It covers operating years from 1905 to 2025. Every power plant in the United States is required to respond to these surveys, which gives the US federal government a high-confidence estimate about the available capacity in the United States.

**The Midcontinent Independent System Operator Generator Interactive Queue** - The raw data from the MISO queue is 3549 interconnection applications for power plants with 24 columns (distinct from generators). It is sourced directly from the MISO website at https://www.misoenergy.org/planning/resource-utilization/GI_Queue/gi-interactive-queue/. The clean dataset includes applications entered in 2015 to 2025 with 3736 rows and 10 columns. The increase in rows is due to expanding power plants into distinct generators for Hybrid Projects. The Midcontinent Independent System Operator is one of many "regional transmission owners" that decides whether a project is allowed to use the transmission lines. This data is de facto the list of all future possible power plants within its physical territory in the United States, making it perfect for future-looking analysis. It is important to note that while MISO projects may be in a certain state, that does not mean MISO is every project in that state. For example, MISO has a small regional footprint in Texas but is just a fraction of the total generation in Texas which is primarily served by ERCOT.

#### Data Processing

This study required a relatively extensive set of data processing to ensure usability and a 1:1 standard between the two datasets. At a high level, they can be described as:

<ol>
  <li>*Collapsing Technologies:* All variations of generating facility and/or technology were standardized to the same basic category groups</li>
  <li>*Missing Values:* No missing values for relevant columns existed in the EIA data. Missing values were largely eliminated as a by-product of the filtering process in MISO. However, in the cases where they remained (missing technology), manual look-up concluded they could not be inputed at scale and were removed.</li>
  <li>*API Handling*:</li> The EIA API required proper handling for a 5,000 row call limit. Relevant error checks and pagination was implemented and then cross-referenced with the online data-puller row and column count to ensure accuracy.
  <li>*Date Coercion:* Date columns needed to be standardized to date format for use in time analysis</li>
</ol>

### Most Common Key Variables

While these datasets had many variables of interest, there are three major variables that form the basis of the recommendations and insight generation. 

**Megawatt Capacity (capacity_mw):** For the purposes of this analaysis, megawatt capacity is the maximum output of electricity a generating unit is capable of. It does not always produce at this level, but it is theoretically capable of doing so. Higher numeric values mean higher capability to produce megawatts. The EIA dataset provides a direct variable to represent this information. The MISO dataset required a calculation based on the max of summer_mw and winter_mw to compute nameplate_capacity.  

**Technology (technology):** Technology is a constructed categorical variable made from a far larger list of sub-category technologies across the EIA and MISO dataset. Both datasets treat these things slightly differently, requiring manual review and re-categorization across technology, fuel, and generating_facility variables. The final buckets constructed are: Coal, Natural Gas, Nuclear, Solar, Wind, Batteries, and Other. Other is a broad group inclusive of technologies such as geothermal and hydroelectric. 

**Clean (clean):** Clean is a binary categorical variable that can take on Clean or Non-Clean relative to the value of technology for a given power plant. “Clean” if technology is in Solar, Wind, Batteries, Nuclear, Conventional Hydroelectric, Geothermal, Hydroelectric Pumped Storage; else “Non-Clean”.





### Analytical Framework and Statistical Methods

This study relies primarily on descriptive statistical techniques to better understand the green transition - how well it's doing and where there are slowdowns. This study does not attempt to attach causal explanations to any technological or policy development, but does attempt to map these possible explanatory variables to support future more causal research. With that said, this study leverages a few techniques.

**Time Series Visualization:** Plotting of megawatt additions by technology groups to identify possible associations with policy and technological developments.

**Geographic Mapping:** Choropleth maps to identify the current state of clean energy and the concentration of its market penetration.

**Composition and Concentration Analysis:** Summary tables and normalized crosstab analysis to understand the distribution of clean energy and technology groups relative to each other and geographically.

**Policy Time Bucketing:** Time buckets surrounding the timeline of the Inflation Reduction Act and comparison rates to see impact on future energy trends.


```{python}
# Standard library imports
import os
import time

# Third-party imports
import requests
import pandas as pd
from dotenv import load_dotenv, find_dotenv
from janitor import clean_names
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import seaborn.objects as so
from matplotlib.ticker import FuncFormatter
import plotly.express as px
import us
from IPython.display import display, Markdown

```



```{python}
## API Set-Up
# Load API key
load_dotenv(find_dotenv(usecwd=True))
API_KEY = os.getenv("API_KEY")
if not API_KEY:
    raise SystemExit("API key not found in .env (API_KEY).")

```

```{python}

# Query Data from the EIA API
BASE_URL = "https://api.eia.gov/v2/electricity/operating-generator-capacity/data/"

# Set length to max 5000 rows per EIA API documentation
LENGTH = 5000  
# Shared params
params = {
    "api_key": API_KEY,
    "frequency": "monthly",
    "start": "2025-07",
    "end": "2025-07",
    "data[0]": "county",
    "data[1]": "latitude",
    "data[2]": "longitude",
    "data[3]": "nameplate-capacity-mw",
    "data[4]": "operating-year-month",
    "data[5]": "planned-retirement-year-month",
    "sort[0][column]": "plantid",
    "sort[0][direction]": "asc",
    "length": LENGTH,
    "offset": 0,
}

# Function to paginate through results, given EIA 5k row limit
def get_page(p):
    backoff = 1
    for _ in range(5):
        r = requests.get(BASE_URL, params=p, timeout=60)
        if r.status_code == 429 or 500 <= r.status_code < 600:
            time.sleep(backoff)
            backoff = min(backoff * 2, 30)
            continue
        r.raise_for_status()
        return r.json()
    raise RuntimeError(f"Failed after retries. Last status: {r.status_code}, body: {r.text[:400]}")

# First page
j = get_page(params)
resp = j["response"]
total = int(resp.get("total", 0))  # <- cast to int
records = resp["data"]
got = len(records)

# More pages
while got < total:
    params["offset"] += LENGTH
    j = get_page(params)
    page = j["response"]["data"]
    if not page:
        break
    records.extend(page)
    got += len(page)


```


```{python}

## Review Basic Dataframe Structure and Data Exploration

eia_df = pd.DataFrame.from_records(records)

# Download local file of dataframe
#eia_df.to_csv("EIA_Generator_Raw.csv", index=False)

# Import local file of dataframe to avoid repeated API calls
#eia_df = pd.read_csv("EIA_Generator_Raw.csv")

# Clean column names
eia_df = clean_names(eia_df)

# Identify df structure

display(eia_df.info())


# NA review - None of these NAs matter!

display(eia_df.isna().sum().sort_values(ascending=False))
```

```{python}
### Manipulate Columns to Appropriate Types and Selection

eia_df["nameplate_capacity_mw"] = pd.to_numeric(eia_df["nameplate_capacity_mw"], errors="coerce")


# Clean and standardize text because simple todatetime isnt working for dates. Broad regex because not clear on issue
eia_df["operating_year_month"] = (
    eia_df["operating_year_month"]
    .astype(str)
    .str.strip()
    .str.replace("/", "-", regex=False)
    .str.extract(r"(\d{4}-\d{2})")[0]  
)

# Now convert
eia_df["operating_year_month"] = pd.to_datetime(
    eia_df["operating_year_month"], format="%Y-%m", errors="coerce"
)

# Create operating year column from operating_year_month
eia_df["operating_year"] = eia_df["operating_year_month"].dt.year

# Create GW column for easier analysis later
eia_df["capacity_gw"] = eia_df["nameplate_capacity_mw"] / 1000



# Remove columns not needed for analysis

eia_df = eia_df.drop(columns=[
    "period",
    "statename",
    "sector",
    "sectorname",
    "entityid",
    "entityname",
    "plantname",
    "energy_source_code",
    "energy_source_desc",
    "prime_mover_code",
    "balancing_authority_name",
    "status",
    "planned_retirement_year_month",
    "latitude",
    "longitude",
    "unit",
    "nameplate_capacity_mw_units"
])

```



```{python}


# Cast nameplate_capacity_mw to numeric
eia_df["technology"].value_counts()

## Prioritizing utility-scale resources, but what is utility-scale and what is not? Common industry rule is 10 MW or greater OR connected to transmission system. Data is limited to nameplate capacity, so using that as decision rule

# Filter to utility-scale resources (>=10 MW)
eia_df = eia_df[eia_df["nameplate_capacity_mw"] >= 10]

# Show technology by MW summary statistics to inform collapsing categories

mw_summary =  (eia_df.groupby("technology")["nameplate_capacity_mw"]
    .agg(["sum", "median"])
    .assign(share=lambda x: x["sum"] / x["sum"].sum() * 100)
    .sort_values(by="sum", ascending=False)
    .style.set_caption("Total MWs per Technology")
)

mw_summary

```


```{python}
### Create utility-scale filtered dataframe and collapse technologies
# There are too many technologies even after filtering. 
# Many are also out of scope for this project at that level of granularity. Coal, wind, solar, natural gas, nuclear, and batteries are main technologies of interest. Will collapse others into "Other" category


eia_df = eia_df.assign(
    technology_group = "Other"
)

eia_df.loc[eia_df["technology"].str.contains("Natural Gas", case=False, na=False), "technology_group"] = "Natural Gas"
eia_df.loc[eia_df["technology"].str.contains("Coal", case=False, na=False), "technology_group"] = "Coal"
eia_df.loc[eia_df["technology"].str.contains("Wind", case=False, na=False), "technology_group"] = "Wind"
eia_df.loc[eia_df["technology"].str.contains("Solar", case=False, na=False), "technology_group"] = "Solar"
eia_df.loc[eia_df["technology"].str.contains("Nuclear", case=False, na=False), "technology_group"] = "Nuclear"
eia_df.loc[eia_df["technology"].str.contains("Batteries", case=False, na=False), "technology_group"] = "Batteries"


# Create clean/non-clean categories

eia_df = eia_df.assign(
    clean = np.where(eia_df["technology_group"].isin(["Solar", "Wind", "Batteries", "Nuclear"]), "Clean", "Non-Clean")
)

# From technology, find Hydroelectric and geothermal and classify as clean
eia_df["clean"] = np.where(
    eia_df["technology"].isin(["Conventional Hydroelectric", "Geothermal", "Hydroelectric Pumped Storage"]),
    "Clean",
    eia_df["clean"]
)

# Confirm expected result
eia_df.query("technology in ['Conventional Hydroelectric', 'Geothermal', 'Hydroelectric Pumped Storage']").sample(20)

# Change and remove old tech column
eia_df = eia_df.drop(columns="technology").rename(columns={"technology_group": "technology"})

```

```{python}

# Download local file of dataframe
eia_df.to_csv("EIA_Generator_Clean.csv", index=False)
```



```{python}
# Import MISO Queue Data

miso_df = pd.read_csv("MISO_Queue_Raw.csv")

# Clean column names
miso_df = clean_names(miso_df)

# Inspect dataframe structure
miso_df.columns
miso_df.info()



# Understand what nameplate_capacity equivalent is in this data
col_mws = ["summer_mw", "winter_mw", "decision_point_1_eris_mw",
"decision_point_1_nris_mw", "decision_point_2_eris_mw", "decision_point_2_nris_mw"]

miso_df[col_mws].sample(20)


# Understand fuel versus generating_facility for tech type

col_tech = ["fuel", "generating_facility"]

miso_df[col_tech].sample(20)


# Check tech nulls:

tech_nulls = miso_df.query("fuel.isnull() & generating_facility.isnull()")


# Remove columns not needed for analysis

miso_df.drop(columns=[
    "transmission_owner",
    "study_group",
    "study_phase",
    "poi_name",
    "decision_point_1_eris_mw",
    "decision_point_2_eris_mw",
    "decision_point_1_nris_mw",
    "decision_point_2_nris_mw",
    "study_cycle",
    "appl_in_service_date",
    "negotiated_in_service_date",
    "done_date",
    "service_type",
    "post_gia_status"

    ], inplace=True)

# Rename technology column for consistency to prior dataset
miso_df.rename(columns={"fuel": "technology"}, inplace=True)

# Review Nulls Writ Large

miso_df.isna().sum().sort_values(ascending=False)


```



```{python}
### Clean Up The Incorrect Date Columns

# Create function for repetition
def clean_date_column(df, column):
    df[column] = (
        df[column]
        .astype(str)
        .str.extract(r"(\d{4}-\d{2}-\d{2})")[0]
    )
    df[column] = pd.to_datetime(df[column], errors="coerce")
    return df[column]


## Clean Date Columns

# Queue Date
miso_df["queue_date"] = clean_date_column(miso_df, "queue_date")

# Withdrawn Date

miso_df["withdrawn_date"] = clean_date_column(miso_df, "withdrawn_date")

# Check columns are as expected
miso_df.dtypes



```


```{python}
### Create nameplate capacity_mw column

# Take max of summer and winter for the few cases where they are different
miso_df = miso_df.assign(capacity_mw = miso_df[["summer_mw", "winter_mw"]].max(axis=1, skipna=True))

# Remove them now that we don't need them
miso_df.drop(columns=["summer_mw", "winter_mw"], inplace=True)
```



```{python}
### Create Time-Period Columns For Pre-IRA, During IRA, Post-IRA
# Create time buckets based on IRA passage date and One Big Beautiful Bill passage marking the end
time_periods = [
    pd.Timestamp.min,             
    pd.Timestamp("2022-08-15"),
    pd.Timestamp("2025-07-03"),
    pd.Timestamp.max               
]
period_labels = ["Pre-IRA", "During IRA", "Post-IRA"]

# Create time buckets relative to policy milestones. 
# Based on if the project entered the queue during any of the sub-periods
miso_df["ira_new"] = pd.cut(
    miso_df["queue_date"],
    bins=time_periods,
    labels=period_labels,
    right=True
)

# Create time buckets relative to policy milestones. 
# Of projects that withdrew from the queue, bucket based on what sub-period they withdrew in
miso_df["ira_withdraw"] = pd.cut(
    miso_df["withdrawn_date"],
    bins=time_periods,
    labels=period_labels,
    right=True
)


```

#### MISO Technology Expansion Documentation
For the sake of replicability, this data wrangling step requires clear documentation due to its complexity. The logic is documented below.

**Problem 1:** Need to use the same technology groups as the EIA data: **Solar, Wind, Natural Gas, Nuclear, Coal, and Other.**  
To solve this, Problem 2 must first be addressed.

**Problem 2:** The `technology` field includes **Hybrid**, which can represent several technologies (for example, a combined solar and battery plant).  
The goal is to have **zero hybrids** remaining in the `technology` column of the MISO dataframe.

**Logic:**
1. Determine whether the `generating_facility` value indicates:
   - A **new hybrid addition**, or  
   - A **single-technology addition** that makes an existing plant hybrid.  
   - If the latter, reassign `generating_facility` to `technology`.

2. Create a DataFrame of *true hybrids*, identified and reassigned according to the following rules:
   - **Combustion Turbine (Simple Cycle):** Reassign to *Other*  
   - **Steam Turbine (including Nuclear, Geothermal, and Solar Steam):** Reassign to *Other*  
   - **Piston (Engine), Internal Combustion:** Reassign to *Other*  
   - **Wind Turbine:** Reassign to *Wind*  
   - **Photovoltaic:** Reassign to *Solar*  
   - **Battery Storage:** Reassign to *Battery Storage*

3. For **new hybrid additions**, perform the following steps:
   - Parse the `generating_facility` field to identify *n* component technologies:
     - *Solar/Battery* → 2 rows  
     - *Wind/Battery* → 2 rows  
     - *Solar/Wind/Battery* → 3 rows  
     - *Solar/Wind* → 2 rows
   - Expand each record into *n* rows.
   - To prevent double-counting, divide project MW equally among components  
     *(i.e., capacity = total MW / n)*.


```{python}
### Standardize Technology Categories
# Check technology categories
miso_df["technology"].value_counts()

# Deal with nulls - if technology AND generating_facility are missing, there's simply no way to inpute that category 
# Analysis using these is useless

miso_df = miso_df[~(miso_df["generating_facility"].isna() & miso_df["technology"].isna())]




# Comparison value for start of hybrid count
print(miso_df["technology"].value_counts().loc["Hybrid"])




## Reassign  False Hybrids to rename technology 1:1

miso_df.loc[miso_df["generating_facility"].str.contains("Combustion Turbine (Simple Cycle)", case=False, na=False, regex=False), "technology"] = "Natural Gas"

miso_df.loc[miso_df["generating_facility"].str.contains("Steam Turbine (including Nuclear, Geothermal and Solar Steam)", case=False, na=False, regex=False), "technology"] = "Steam Turbine (including Nuclear, Geothermal and Solar Steam)"


miso_df.loc[miso_df["generating_facility"].str.contains("Piston (Engine), Internal Combustion (Diesel)", case=False, na=False, regex = False), "technology"] = "Piston (Engine), Internal Combustion (Diesel)"

miso_df.loc[miso_df["generating_facility"].str.contains("Wind Turbine", case=False, na=False), "technology"] = "Wind"

miso_df.loc[miso_df["generating_facility"].str.contains("Photovoltaic", case=False, na=False), "technology"] = "Solar"

miso_df.loc[miso_df["generating_facility"].str.contains("Battery Storage", case=False, na=False), "technology"] = "Battery Storage"



# True Hybrids

hybrids = miso_df.query("technology == 'Hybrid'").copy()

hybrids["generating_facility"].value_counts()


# Split "Solar/Wind/Battery" → ["Solar","Wind","Battery"], count parts
hybrids["parts"] = hybrids["generating_facility"].str.split("/")
hybrids["n"] = hybrids["parts"].str.len()


hybrid_df = (
    hybrids.explode("parts", ignore_index=True)
           .assign(
               technology=lambda d: d["parts"].str.strip(),
               component_mw=lambda d: d["capacity_mw"] / d["n"]
           )
           .drop(columns=["parts", "n"])
)

hybrid_df["capacity_mw"] = hybrid_df["component_mw"] 

# Add back in hybrids to the MISO df
miso_df = pd.concat([miso_df[miso_df["technology"] != "Hybrid"], hybrid_df], ignore_index=True).drop(columns=["component_mw", "generating_facility"])

miso_df.value_counts("technology")

```



```{python}

# Standardize the categories to EIA established schema
miso_df = miso_df.assign(
    technology_group = "Other"
)

miso_df.loc[miso_df["technology"].str.contains("Combined Cycle", case=False, na=False), "technology_group"] = "Natural Gas"
miso_df.loc[miso_df["technology"].str.contains("Gas", case=False, na=False), "technology_group"] = "Natural Gas"
miso_df.loc[miso_df["technology"].str.contains("Battery Storage", case=False, na=False), "technology_group"] = "Batteries"
miso_df.loc[miso_df["technology"].str.contains("Solar", case=False, na=False), "technology_group"] = "Solar"
miso_df.loc[miso_df["technology"].str.contains("Wind", case=False, na=False), "technology_group"] = "Wind"
miso_df.loc[miso_df["technology"].str.contains("Coal", case=False, na=False), "technology_group"] = "Coal"
miso_df.loc[miso_df["technology"].str.contains("Nuclear", case=False, na=False), "technology_group"] = "Nuclear"



miso_df["technology_group"].value_counts()

# Create clean/non-clean categories. Unclear what the full range of Steam Turbine (including Nuclear, Geothermal and Solar Steam) is, so given small amount of obs and examples mentioning clean, go clean

miso_df = miso_df.assign(
    clean = np.where(
        (
            miso_df["technology_group"].isin(["Solar", "Wind", "Batteries", "Nuclear"])
            | miso_df["technology"].isin(["Hydro", "Steam Turbine (including Nuclear, Geothermal and Solar Steam)"])
        ),
        "Clean",
        "Non-Clean"
    )
)


# Change and remove old tech column
miso_df = miso_df.drop(columns="technology").rename(columns={"technology_group": "technology"})


# Sanity Check results

print(miso_df.query("clean == 'Clean'").value_counts("technology"))
print(miso_df.query("clean == 'Non-Clean'").value_counts("technology"))


```



```{python}
### Clean State Values
# I'm seeing mixed format for states in state col AND nulls
miso_df["state"].unique()


# create name→abbr and abbr→abbr mapping
state_map = {s.name: s.abbr for s in us.states.STATES}
state_map.update({s.abbr: s.abbr for s in us.states.STATES})

miso_df["state"] = miso_df["state"].map(state_map)


```


```{python}

### Final dataframe set-up
# Remove helper columns that helped think about and solve other column issues

miso_df.drop(columns = ["project_#", "county"], inplace = True)

# Create GW column
# Create GW column for easier analysis later
miso_df["capacity_gw"] = miso_df["capacity_mw"] / 1000

# Final Null check

# Review Nulls Writ Large - Perfect. Exactly the values I expect to see nulls

miso_df.isna().sum().sort_values(ascending=False)

# Download Clean

miso_df.to_csv("MISO_Queue_Clean.csv", index=False)

```






## Analysis & Results
The analysis of the newly cleaned data primarily attempts to understand what the energy mix looks like today and how we got here. Was there a steady increase in certain forms of technology? Or was there lumpy development that caused skyrocketing share increases? Building upon the status quo of the electricity mix, the MISO data looks towards the future to see what we can expect to see coming online in the next decade. Is this future generation more of the same or different from our legacy generation? To start, this work depicts the national-level data for generators.

```{python}

# Check Technology Breakdown with Summary Stats
tech_breakdown_summ = (eia_df.groupby("technology")["nameplate_capacity_mw"].describe().style.set_caption("Summary Statistics - MW by Technology"))

tech_breakdown_summ

percentage_fuel_mix = (
    pd.crosstab(
        index=eia_df["technology"],
        columns="share",
        values=eia_df["nameplate_capacity_mw"],
        aggfunc="sum",
        normalize="columns"
    )
    .mul(100)
    .sort_values(by="share", ascending=False)
    .round(1)
    .style.format("{:.1f}%")
    .set_caption("Percentage Share of Total Capacity by Technology")
)

display(percentage_fuel_mix)

# Boxplot of nameplate capacity by technology

eia_df.boxplot(column="nameplate_capacity_mw", by="technology", vert=False, figsize=(10,6))
plt.title("Nameplate Capacity by Technology (MW)")
plt.suptitle("")
plt.ylabel("")      
plt.tight_layout()
plt.show()

```

#### National Statistics
These results are not all that surprising. The US relies heavily on its baseload power, such as natural gas and coal, to meet its electricity needs. These results show that today in the US more than 50% of available generation capacity comes from fossil fuels. Wind and solar only make up around 20% of the total. At least in terms of our fuel mix today, it seems our grid is still incredibly reliant on fossil fuels. It is unlikely our current mix is sufficient to meet US carbon targets. This snapshot of July 2025 is helpful to understand where we are today, but it does not provide much actionable information about how we got here or if there is momentum behind any one technology that we would expect to shake up the percentages in the long-run. This requires moving onto more granular analysis.


As an aside, the boxplot helps characterize the differences between legacy power plants and more modern renewables. Nuclear, coal, and natural gas seem to have much higher median capacity sizes relative to solar and wind, which suggests future clean energy needs will require more power plants per MW unless nuclear, which has a better density profile than even coal and natural gas, sees a resurgence.

```{python}
### Show annual additions by technology over time

# Order and colors
order = ["Coal", "Natural Gas", "Nuclear", "Wind", "Solar", "Batteries", "Other"]
colors = {
    "Coal": "#595959", "Natural Gas": "#1f77b4", "Solar": "#ffcc00",
    "Wind": "#2ca02c", "Nuclear": "#9467bd", "Batteries": "#ff7f0e",
    "Other": "#c7c7c7",
}

# Year x technology matrix
pivot_df = (
    eia_df.query("operating_year > 1950")
          .groupby(["operating_year", "technology"], observed=True)["capacity_gw"]
          .sum()
          .unstack(fill_value=0)
          .reindex(columns=order, fill_value=0)
)

# Plot
ax = pivot_df.plot.area(
    figsize=(11, 6),
    linewidth=0,
    alpha=0.95,
    color=[colors.get(c, "#CBD5E1") for c in pivot_df.columns],
)

ax.set(title="Annual Capacity Additions by Technology",
       xlabel="", ylabel="Added Capacity (GW)")
ax.legend(title="Technology", loc="upper left", frameon=False)
ax.margins(x=0)
plt.tight_layout()
plt.show()



### Cumulative Additions
# --- prep ---
annual = eia_df

annual = (
    annual.groupby(["operating_year", "technology"])["capacity_gw"]
          .sum().unstack(fill_value=0).sort_index()
)

cumul = annual.cumsum()
cumul.index = pd.to_numeric(cumul.index, errors="coerce")
cumul = cumul.loc[(cumul.index >= 1950) & (cumul.index <= 2025)]

# --- colors ---
colors = {
    "Coal":        "#595959",
    "Natural Gas": "#1f77b4",
    "Solar":       "#ffcc00",
    "Wind":        "#2ca02c",
    "Nuclear":     "#9467bd",
    "Batteries":   "#ff7f0e",
    "Other":       "#c7c7c7",
}

# order by final-year contribution for stack and legend
order = cumul.iloc[-1].sort_values(ascending=False).index.tolist()

# long-form for seaborn.objects
plot_df = (
    cumul.reset_index(names="operating_year")
       [[ "operating_year", *order ]]
       .melt(id_vars="operating_year", var_name="technology", value_name="capacity_gw")
)

# palette aligned to order
palette = {k: colors.get(k, "#c7c7c7") for k in order}

# theme
sns.set_theme(style="whitegrid", rc={
    "axes.spines.top": False,
    "axes.spines.right": False,
    "grid.alpha": 0.2,
    "axes.titlepad": 12,
})

fmt_gw = FuncFormatter(lambda v, _: f"{v:,.0f}")

# --- plot ---
p = (
    so.Plot(plot_df, x="operating_year", y="capacity_gw", color="technology")
      .add(so.Area(alpha=0.95), so.Stack())
      .scale(color=palette)
      .limit(x=(1950, 2025), y=(0, None))
)

fig = p.on(plt.figure(figsize=(11, 6))).plot()
ax = plt.gca()  # current Axes from the just-plotted figure

# legend with ordered labels
handles, labels = ax.get_legend_handles_labels()
idx = {lab: i for i, lab in enumerate(order)}
pairs = sorted(zip(handles, labels), key=lambda hl: idx.get(hl[1], 1_000))
handles, labels = zip(*pairs) if pairs else (handles, labels)

ax.legend(handles, labels, title="Technology", loc="upper left", ncols=2, frameon=False)

# remove the automatic legend created by seaborn.objects
ax.get_legend().set_title(None)
ax.get_legend().remove()

# titles and formatting
ax.set_title("Cumulative Installed Capacity by Technology")
ax.set_xlabel("")
ax.set_ylabel("Installed Capacity (GW)")
ax.yaxis.set_major_formatter(fmt_gw)

plt.tight_layout()
plt.show()

```

#### Annual Capacity and Cumulative Additions

These time series better depicts how the US got to its current fuel mix and better depicts the momentum behind each technology. A few major insights pop out:

**Coal's Prime Time:** Coal is not a mover of the 21st century. Despite being a significant part of the current US fuel mix, the vast majority of coal seems to have been added between 1965 and 1985. Since roughly 2015, it seems that almost no coal has come online. This suggests that coal is a legacy resource that absent any substantial change in the policy environment, may continue to no longer be added at scale. This could be a sign for a cleaner grid unless its replaced by a different fossil fuel source, such as natural gas.

**Natural Gas - The Apex Predator:** Natural gas is the star of this graph. The shale revolution of the 2000s, where fracking and horizontal drilling burst onto the scene, is a massive spike on the graph that exclipses any other additions. No other energy source at any time period has come close to this amount of year-to-year added capacity. Given the absence of wind, solar, or nuclear showing up in the early 2000s, it seems that natural gas was the main replacement for coal additions in this period. While natural gas is not clean in absolute terms, it is certainly much cleaner than coal, which is a promising sign to some degree. Nothing about this graph seems to indicate natural gas expansion is stopping anytime soon, but its relative share could be cut into, just like it did to coal.

**Wind and Solar - The New Era:** Wind and solar seem to be the new players on the block with substantial additions from the mid 2000s and on, following the natural gas peak. Wind seems to have been the major clean player in the early 2010s with solar breaking out and skyrocketing after it. By the end of this time series, it seems like clean generation is the vast majority of new generation in the past 5 years. However, as the national data indicates, that means clean energy is still playing catchup to a a massive fossil fuel-based market share. The cumulative graph clearly depicts the early-bird advantage from the shale revolution that firmly planted itself as the leader of electricity generation. To better understand if we can expect this trend to continue to give renewables (and clean energy broadly) a chance to replace natural gas, we need more future-looking evidence, such as the MISO data, and we need to see if these trends are replicated across the US or concentrated in certain states. A secondary insight is that the Inflation Reduction Act seems to overlap with some of the solar spike but oddly seems to coincide with a decline in wind relative to solar.


The geographic distribution in the EIA and MISO data can be seen below.
```{python}
### Geographic Distribution of Clean vs Non-Clean Capacity
# 0) Normalize clean to boolean
map_clean = {True: True, False: False, "Clean": True, "Non-Clean": False}
eia_df["is_clean"] = eia_df["clean"].map(map_clean)

# 1) Aggregate and get clean/non-clean columns
agg = (
    eia_df.groupby(["stateid", "is_clean"])["capacity_gw"]
          .sum()
          .unstack(fill_value=0)
          .rename(columns={True: "clean_gw", False: "nonclean_gw"})
          .reset_index()
)

# 2) Shares and totals
state_share = (
    agg.assign(total=lambda d: d["clean_gw"] + d["nonclean_gw"])
       .assign(clean_share=lambda d: d["clean_gw"] / d["total"])
)
state_share["pct_clean"] = (state_share["clean_share"] * 100).round(1)

# define color threshold
state_share["text_color"] = state_share["clean_share"].apply(
    lambda x: "white" if x < 0.35 else "black"
)

# 3) Choropleth colored by % clean
fig = px.choropleth(
    state_share,
    locations="stateid",
    locationmode="USA-states",
    color="clean_share",
    color_continuous_scale=[
        # Dirty
        (0.0, "#7f3b08"),  
        (0.25, "#b35806"),
        # Neutral
        (0.5, "#f7f7f7"),   
        (0.75, "#4daf4a"),
        # Clean
        (1.0, "#006837")    
    ],
    range_color=[0, 1],
    hover_data={"pct_clean": True, "clean_share": False, "total": True},
    height=500,
    labels={"clean_share": "% Clean"}
)

# 4) Focus on US 
fig.update_geos(
    scope="usa",
    projection_type="albers usa",
    center=dict(lat=38, lon=-96),
    projection_scale=0.95,          
    showframe=False,
    showcoastlines=True
)

fig.update_layout(
    title=dict(
        text=(
            "United States Clean Capacity Penetration by State"
            "<br><sup>Labels show total installed capacity (GW)</sup>"
        ),
        x=0.5
    ),
    margin=dict(l=0, r=0, t=80, b=0)
)

# 5) Create labels and mask for text color
state_share["label"] = state_share["total"].map(lambda x: f"{x:.1f}")
mask_dark = state_share["clean_share"] < 0.35

# dark states → white text
fig.add_scattergeo(
    locations=state_share.loc[mask_dark, "stateid"],
    locationmode="USA-states",
    text=state_share.loc[mask_dark, "label"],
    mode="text",
    hoverinfo="skip",
    textfont=dict(size=10, color="white")
)

# others → black text
fig.add_scattergeo(
    locations=state_share.loc[~mask_dark, "stateid"],
    locationmode="USA-states",
    text=state_share.loc[~mask_dark, "label"],
    mode="text",
    hoverinfo="skip",
    textfont=dict(size=10, color="black")
)

fig.update_layout(showlegend=False)

fig.show()

## MISO Map


active_miso_df = miso_df.query("request_status == 'Active'").copy()

# 0) Normalize clean to boolean
map_clean = {True: True, False: False, "Clean": True, "Non-Clean": False}
active_miso_df["is_clean"] = active_miso_df["clean"].map(map_clean)

# 1) Aggregate and get clean/non-clean columns
agg = (
    active_miso_df.groupby(["state", "is_clean"])["capacity_gw"]
          .sum()
          .unstack(fill_value=0)
          .rename(columns={True: "clean_gw", False: "nonclean_gw"})
          .reset_index()
)

# 2) Shares and totals
state_share = (
    agg.assign(total=lambda d: d["clean_gw"] + d["nonclean_gw"])
       .assign(clean_share=lambda d: d["clean_gw"] / d["total"])
)
state_share["pct_clean"] = (state_share["clean_share"] * 100).round(1)

# Format text
text=state_share["total"].apply(lambda x: f"{x:.1f}")


# 3) Choropleth colored by % clean
fig = px.choropleth(
    state_share,
    locations="state",
    locationmode="USA-states",
    color="clean_share",
    color_continuous_scale=[
        # Dirty
        (0.0, "#7f3b08"),  
        (0.25, "#b35806"),
        # Neutral
        (0.5, "#f7f7f7"),   
        (0.75, "#4daf4a"),
        # Clean
        (1.0, "#006837")    
    ],
    range_color=[0, 1],
    hover_data={"pct_clean": True, "clean_share": False, "total": True},
    height=500,
    labels={"clean_share": "% Clean"}
)

# 4) Focus on US 
fig.update_geos(
    scope="usa",
    projection_type="albers usa",
    center=dict(lat=38, lon=-96),
    projection_scale=0.95,          
    showframe=False,
    showcoastlines=True
)

fig.update_layout(
    title=dict(
        text=(
            "MISO Future Clean Capacity Penetration by State"
            "<br><sup>Labels show total capacity (GW) actively applied for by developers (GW)</sup>"
        ),
        x=0.5
    ),
    margin=dict(l=0, r=0, t=80, b=0)
)




# GW Labels
fig.add_scattergeo(
    locations=state_share["state"],
    locationmode="USA-states",
     text=state_share["total"].apply(lambda x: f"{x:.1f}"),
    mode="text",
    hoverinfo="skip",
    textfont=dict(size=10, color="black")
)

fig.update_layout(showlegend=False)

fig.show()

```


#### Geographic Distribtion

Here we have two distinct maps that show the current fuel mix across the US and the future MISO queue data in terms of a clean, non-clean ratio. This analysis allows us to better understand the nature of where energy is being concentrated.

Notably, the United States clean energy mix is heavily concentrated in the West. The Eastern part of the United States has a very high ratio of non-clean energy resources. This distribution suggests that any future clean energy efforts would necessitate a very strategic implementation to ensure the East follows in the path of the West.

The story is very different when we move to future-looking data with MISO. While just a subset of the United States, the clean percentage is dramatically different for the middle part of the United States. Every single state's future energy resources in the queue is well above the 50% mark for clean energy. Assuming the attrition rate for projects in this queue is the same across technologies, we would expect the tail end of the annual added capacity graph to continue forward into the future. This assumes nothing fundamentally changes about the incentives for clean energy resources, which recent policy developments with the One Big Beautiful Bill suggest is too optimistic. To characterise why this matters, it is valuable to isolate the distribution of these different types of projects that bring extensive capital wherever they are located.

```{python}
### Determine Distribution of Energy Resources - Q: Is capital investment centralized or distributed? Use counties per MW as a proxy.
# Calculate total MW per technology
technology_mws = (
    eia_df.groupby("technology")["nameplate_capacity_mw"]
    .sum()
    .sort_index(ascending=False)
)

# Calculate unique counties per technology
technology_counties = (
    eia_df.groupby("technology")["county"]
    .nunique()
    .sort_index(ascending=False)
    
)

# Combine both into one DataFrame
distribution_df = pd.concat([technology_mws, technology_counties], axis=1)
distribution_df.columns = ["Total MW", "Unique Counties"]

# Add MW per County metric
distribution_df["MW per County"] = (
    distribution_df["Total MW"] / distribution_df["Unique Counties"]
)

# Rearrange columns for mW per county first

distribution_df = distribution_df[["MW per County", "Total MW", "Unique Counties"]]
# Format output
distribution = (
    distribution_df.sort_values("MW per County", ascending=False)
    .style.format("{:,.0f}")
    .set_caption("Concentration of Energy Resources Across Counties")
)

distribution


```

#### Geographic Concentration - Counties

While a simplistic measure, it is valuable to review this data. Here, the study takes the total MW for a technology group and divides it by the number of unique counties. In essence, it asks how distributed are these "clean" megawatts across communities relative to their non-clean counterparts. The data is quite striking in terms of renewables but not nuclear. Wind and solar show less than half the coal, nuclear, and natural gas MW per county value. This information suggests that a world with more wind and solar as a broader share of the energy mix may diversify the economic development gains from capital investment to a greater number of communities. A policy shift away from these energy resources could re-entrench wealth into a smaller set of counties. Further causal analysis is warranted, but this information is interesting.

#### Future of Energy - MISO Interconnection Queue

**How has the IRA and its reduction under the “Big Beautiful Bill” changed the fuel mix of new generation interconnections?**

1. Are clean energy projects entering the queue less after the “Big Beautiful Bill”?
2. Are clean energy projects withdrawing at a faster rate after the “Big Beautiful Bill”?

```{python}


# Filter to clean energy projects that actually withdrew and entered new
clean_withdraws = miso_df.query("clean == 'Clean' and withdrawn_date.notna()")
clean_new = miso_df.query("clean == 'Clean'")

# Count withdrawals by IRA period
withdraw_counts = clean_withdraws["ira_withdraw"].value_counts()
new_counts = clean_new["ira_new"].value_counts()

# Define how many months are in each period

months_pre = len(pd.date_range(miso_df["withdrawn_date"].min(), "2022-08-15", freq = "MS"))
months_during = len(pd.date_range("2022-08-16", "2025-07-03", freq="MS"))
months_post = len(pd.date_range("2025-07-04", miso_df["withdrawn_date"].max(), freq="MS"))



# Given:
# withdraw_counts (index: "During IRA", "Post-IRA")
# months_during, months_post

months = pd.Series(
    {"Pre-IRA": months_pre, "During IRA": months_during, "Post-IRA": months_post},
    name="months"
)

rates = (
    pd.DataFrame({
        "withdrawn": withdraw_counts,
        "new_clean": new_counts
    })
    .reindex(months.index, fill_value=0)
    .join(months)
    .assign(withdraws_per_month=lambda d: (d["withdrawn"] / d["months"]).round(1))
    .assign(new_per_month=lambda d: (d["new_clean"] / d["months"]).round(1))
    .astype({"withdrawn": int, "new_clean": int})
)

order = ["Pre-IRA", "During IRA", "Post-IRA"]

rates = (
    rates.reindex(order)
    .style.format("{:,.0f}")
    .set_caption("Clean Energy Projects - Withdrawals and New Entrants Per Month")
)

rates

```

#### Review of the Future Evidence

The evidence is far from conclusive on whether the Big Beautiful Bill and Inflation Reduction Act's cutbacks have a meaningful impact on clean energy buildout due to data limitations. Unfortunately, given the recent nature of the One Big Beautiful Bill in July and the long timeline of energy projects, it is difficult to parse strong signals from this data.

The evidence for new entrants is largely inconclusive. It could indicate fewer projects are entering per month than others, but given the actual timing for when projects can apply to MISO (not every month), this study assigns very low informative power to this data at this low a sample size.

However, the withdrawals_per_month rate and absolute count of withdrawals are very striking. Despite the Post-IRA period only being 3 months long, the Post-IRA period's withdrawals are almost the same amount as the other periods that are 10 and 20 times longer. This effect may not pan out in the long term as meaningful, but it would be difficult to not associate some drastic change in clean energy developers' views of the viability of their projects in this period.

## Conclusions & Recommendations

### Key Findings and Discussion

**1. No Single Technology Is Untouchable**  
Technological additions fluctuate substantially across sub-periods and appear sensitive to both policy changes and innovation cycles.  For example, the shale revolution caused natural gas to overtake coal's market share, and shortly after, wind and solar began cutting into its share following technological improvements and policy interventions.  It seems prudent to leverage a dual-pronged technology R&D and policy incentive structure to ensure more clean energy buildout.  Thus, targeted policy incentives can meaningfully steer development toward clean energy.

**2. Clean Energy Is Not Distributed Uniformly**  
The western United States dominates clean-energy buildout.  Future research could better parse out why this is the case, but it is important that every state is willing and able to engage in the green transition.  If there are state holdouts and carbon capture does not take hold, Net Zero seems out of reach.  Accordingly, policymakers should consider regional equity to ensure the economic benefits of the transition are more evenly shared.  This is especially true considering the coal towns of the East are hit the hardest from the transition, which can cause societal incohesion and distrust.  A just and equitable energy transition must include these groups.

**3. Renewables Are More Geographically Dispersed**  
Within any given state, renewable technologies tend to span more counties and communities.  If more counties are going to see energy resources, that means their identity may increasingly be tied to renewables.  The more personal attachment there is to an energy resource, the easier it is to create coalitions and advocates for clean energy buildout.  This wider footprint suggests that more Americans can experience local economic benefits—an argument that may strengthen public and political support for renewables.  This provides ample opportunity and risk. Diligent engagement is necessary.

**4. Policy Matters — Advocate for Non-Obstructive Policy**  
The *Big Beautiful Bill* and the *Inflation Reduction Act (IRA)* correspond to a marked shift in clean-energy project behavior, including increased withdrawals immediately following the IRA's passage.  
Policy matters, and market forces, despite making solar and wind very cheap, are not enough.  A hostile environment can cause a chilling effect that crowds out renewables.  As Point 1 indicates, no single technology is dominant.  If a clean energy transition is on the horizon, it will require constant policy pressure, and the evidence underscores that markets alone do not dictate capacity expansion. Policy design remains a decisive factor.

---

### Suggestions

- Protect non-obstructive policy and streamline siting to avoid chilling effects.
- Use visible, county-level benefits to sustain coalitions for renewable deployment.
- Track project attrition and queue dynamics closely after major policy changes.


---

### Future Work



There is room for further work on this topic to better understand the future of clean energy.  
Possible extensions include:

- Apply **causal inference** to estimate the impact of the *Inflation Reduction Act* and the *Big Beautiful Bill* on megawatt capacity.  
- Include more **regional transmission operator queues** (e.g., PJM, SPP) to create a more nationally representative sample of future capacity.  
- **Web scrape** MISO documentation at the project level to impute missing project data.  
- **Repeat this analysis** one year later. Descriptive power would dramatically increase a year out from the *Big Beautiful Bill*, rather than three months.  
- Apply **statistical inference tests** (two-proportion *z*-tests and Fisher’s exact tests) to compare withdrawal and new-entry rates across policy periods.
